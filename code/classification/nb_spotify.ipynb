{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sf9zRRGflNNm",
    "outputId": "477597d7-aa69-42ab-aa94-037ea0ef3662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark==3.0.1\n",
      "  Downloading pyspark-3.0.1.tar.gz (204.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 204.2 MB 33 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 48.4 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612246 sha256=26acb31d3b1c91df7a832bed0a5f0b4483aaee59525bc0f655d65f068d6c58b5\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/34/fa/b37b5cef503fc5148b478b2495043ba61b079120b7ff379f9b\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.0.1 py4j==0.10.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8K7mUm_blP2a"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql.types import IntegerType,BooleanType,DateType,FloatType\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"8g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlvCKVfDlRft",
    "outputId": "c6ecbae3-869d-4577-9157-a3bc2562f478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive    \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qXAjrhAnlTBv"
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet('../../data/cleanedDataset_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwX95qki_ZSi",
    "outputId": "9abd4f6c-96fe-404b-9f7e-2766b4e5c238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----------+--------------------+------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+--------------------+---------------------+--------------------+---------------------+------------------+\n",
      "|            id_track|popularity_track|duration_ms|              genres|release_date|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|time_signature|sum_artist_followers|sum_artist_popularity|avg_artist_followers|avg_artist_popularity|               age|\n",
      "+--------------------+----------------+-----------+--------------------+------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+--------------------+---------------------+--------------------+---------------------+------------------+\n",
      "|00AeAaSNbe92PRrst...|               3|     156067|[classic czech po...|  1980-01-01|       0.602| 0.552|  0|  -6.667|   1|      0.404|       0.658|             0.0|  0.0972|   0.65|182.229|             3|               10807|                   80|              5403.5|                 40.0| 41.83013698630137|\n",
      "|00DJt4PjkzeXhKKVD...|               9|     220133|[afrobeat, afropo...|  1976-01-01|        0.77| 0.891|  1|  -7.306|   1|      0.172|       0.543|         7.96E-4|  0.0684|  0.898|135.573|             4|               19833|                   43|             19833.0|                 43.0| 45.83287671232877|\n",
      "|00HgVIkZrAL8WjAN9...|              33|     250960|[alternative meta...|  1996-02-20|       0.212| 0.986|  0|   -6.69|   0|       0.14|      4.8E-5|           0.918|   0.324|  0.231|140.917|             4|              874600|                   68|            874600.0|                 68.0|25.682191780821917|\n",
      "|00Lx2f8NRiFKMGWa0...|              35|     457040|[corrosion, dark ...|  1990-01-01|       0.362| 0.453| 11| -17.744|   0|     0.0398|       0.144|           0.827|   0.117|  0.257|118.853|             4|               69129|                   42|             69129.0|                 42.0| 31.82191780821918|\n",
      "|00fzPML4lrNag28OP...|              52|     282891|[brazilian rock, ...|  2017-09-22|       0.343| 0.225|  1| -14.937|   0|     0.0384|       0.957|         2.49E-4|   0.661|  0.101|144.533|             4|             1709414|                   68|           1709414.0|                 68.0| 4.079452054794521|\n",
      "+--------------------+----------------+-----------+--------------------+------------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+--------------------+---------------------+--------------------+---------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7Ac6ppZa_ilo"
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"loudness\") #perchè ha valori negativi e il nb non li accetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Wm4wRZ8LlUlJ"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import QuantileDiscretizer \n",
    "\n",
    "qds = QuantileDiscretizer(relativeError=0.0001, handleInvalid=\"error\", numBuckets=10, inputCol=\"popularity_track\", outputCol=\"label\")\n",
    "\n",
    "df = qds.setHandleInvalid(\"keep\").fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "elQKmCTllYnS"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf, StringType\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XFONfm2flacg"
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler( \n",
    "inputCols=['age',\n",
    " 'duration_ms',\n",
    " 'danceability',\n",
    " 'energy',\n",
    " 'key',\n",
    " 'mode',\n",
    " 'speechiness',\n",
    " 'acousticness',\n",
    " 'instrumentalness',\n",
    " 'liveness',\n",
    " 'valence',\n",
    " 'tempo',\n",
    " 'time_signature',\n",
    " 'avg_artist_followers',\n",
    " 'avg_artist_popularity',\n",
    " 'sum_artist_followers',\n",
    " 'sum_artist_popularity'], \n",
    "outputCol=\"features\")\n",
    "output=assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jD3Fkwvzlm9S"
   },
   "outputs": [],
   "source": [
    "final_data = output.select( \"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "u2Wj-gwcN2FQ"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "# Compute summary statistics by fitting the StandardScaler\n",
    "scalerModel = scaler.fit(final_data)\n",
    "\n",
    "# Normalize each feature to have unit standard deviation.\n",
    "df = scalerModel.transform(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ogNgSkQLlrHR"
   },
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3], seed = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EuAE5rTllwy3"
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "nbModel = nb.fit(train)\n",
    "predictions = nbModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYy9X2VSl4ZQ",
    "outputId": "732c0b5c-bcd2-4dd6-b04f-14a84f39e953"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14489503626227526"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eNSBRGdl8Ot"
   },
   "source": [
    "# NB with filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('../../data/cleanedDatasetFiltered_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14489503626227526"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(\"loudness\") #perchè ha valori negativi e il nb non li accetta\n",
    "\n",
    "qds = QuantileDiscretizer(relativeError=0.0001, handleInvalid=\"error\", numBuckets=10, inputCol=\"popularity_track\", outputCol=\"label\")\n",
    "\n",
    "df = qds.setHandleInvalid(\"keep\").fit(df).transform(df)\n",
    "\n",
    "final_data = output.select( \"features\", \"label\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "# Compute summary statistics by fitting the StandardScaler\n",
    "scalerModel = scaler.fit(final_data)\n",
    "\n",
    "# Normalize each feature to have unit standard deviation.\n",
    "df = scalerModel.transform(final_data)\n",
    "\n",
    "train, test = df.randomSplit([0.7, 0.3], seed = 10)\n",
    "\n",
    "nb = NaiveBayes()\n",
    "nbModel = nb.fit(train)\n",
    "predictions = nbModel.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nb_spotify.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
