{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "one_vs_others.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHMBmH8NfE4L",
        "outputId": "d1071c36-3135-461a-d7a1-7f2de34ab005"
      },
      "source": [
        "!pip install pyspark==3.0.1 py4j==0.10.9"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.0.1\n",
            "  Downloading pyspark-3.0.1.tar.gz (204.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 204.2 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 44.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612246 sha256=4cffc0e59db3a175945e646a879ae71b8c5a02b454154bbe96429dd4c71a78e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/34/fa/b37b5cef503fc5148b478b2495043ba61b079120b7ff379f9b\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHaVdJIYfPP6"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.sql.types import IntegerType,BooleanType,DateType,FloatType\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local[*]\")\\\n",
        "        .appName('spotify_classification')\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVKHlt3Vff8h",
        "outputId": "fad2b6f3-95c9-45d9-9b79-9f72a52734d7"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99K8xJVBfl6x"
      },
      "source": [
        "df = spark.read.json(\"drive/My Drive/spot_data.json\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAH7yi2ngCDa"
      },
      "source": [
        "from pyspark.ml.feature import Bucketizer\n",
        "bucketBorders=[0,10,20,30,40,50,60,70,80,90,100]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb_PJiSygEfv"
      },
      "source": [
        "bucketer=Bucketizer().setSplits(bucketBorders).setInputCol(\"popularity_track\").setOutputCol(\"label\")\n",
        "df_buck = bucketer.transform(df)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrGOV_LEgHOd"
      },
      "source": [
        "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import udf, StringType\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcxwuyijgJuv"
      },
      "source": [
        "assembler = VectorAssembler( \n",
        "inputCols=['age',\n",
        " 'duration_ms',\n",
        " 'danceability',\n",
        " 'energy',\n",
        " 'key',\n",
        " 'loudness',\n",
        " 'mode',\n",
        " 'speechiness',\n",
        " 'acousticness',\n",
        " 'instrumentalness',\n",
        " 'liveness',\n",
        " 'valence',\n",
        " 'tempo',\n",
        " 'time_signature',\n",
        " 'sum_artist_followers',\n",
        " 'sum_artist_popularity'], \n",
        "outputCol=\"features\")\n",
        "output=assembler.transform(df_buck)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5CHeY4UgLVn"
      },
      "source": [
        "final_data = output.select( \"features\", \"label\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6bwqpiigOmO"
      },
      "source": [
        "train, test = final_data.randomSplit([0.7, 0.3], seed = 10)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4evUZmvLgRPE"
      },
      "source": [
        "lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhW4PDYMhIyR"
      },
      "source": [
        "ovr = OneVsRest(classifier=lr)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EweE2WEtgcUI"
      },
      "source": [
        "ovrModel = ovr.fit(train)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIDpHdkpggiw"
      },
      "source": [
        "predictions = ovrModel.transform(test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHV5zrQ0giwU"
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty4-kVmXgk1i",
        "outputId": "8e8a5e25-60df-4970-930e-b558d5a55e36"
      },
      "source": [
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.659921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpriYYMfgobA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}